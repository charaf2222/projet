<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenCV JS Camera</title>
    <script async src="js/opencv.js" onload="openCvReady();"></script>
    <script src="js/utils.js"></script>
    <style>
        body, html {
            height: 100%;
            margin: 0;
            background-color: #333;
            color: #fff;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            font-family: Arial, sans-serif;
        }
        #videoWrapper {
            width: 80%;
            margin-top: 20px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            display: flex;
            justify-content: center;
            background: #000;
        }
        canvas {
            width: 100%;
            display: block; /* Remove extra space below the canvas */
        }
        button {
            padding: 10px 20px;
            margin-top: 20px;
            font-size: 16px;
            background-color: #007BFF;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <div id="videoWrapper">
        <video id="cam_input" autoplay playsinline width="640" height="480" style="display: none;"></video>
        <canvas id="canvas_output" width="640" height="480"></canvas>
    </div>
    <button id="stopButton" onclick="stopCamera()">Stop Camera</button>
<script type="text/JavaScript">
    // Votre code JavaScript ici
    let videoStream;

    function openCvReady() {
        cv['onRuntimeInitialized']=()=>{
            let video = document.getElementById("cam_input"); // video est l'ID de la balise vidéo
            navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            .then(function(stream) {
                videoStream = stream; // Stocker le flux vidéo pour l'arrêter plus tard
                video.srcObject = stream;
                video.play();
            })
            .catch(function(err) {
                console.log("Une erreur est survenue! " + err);
            });
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
            let gray = new cv.Mat();
            let cap = new cv.VideoCapture(cam_input);
            let faces = new cv.RectVector();
            let classifier = new cv.CascadeClassifier();
            let utils = new Utils('errorMessage');
            test = new cv.Mat();

            let faceCascadeFile = 'haarcascade_frontalface_default.xml'; 
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                classifier.load(faceCascadeFile); // dans le rappel, chargez le cascade depuis le fichier
            });

            const FPS = 12;
            const sizeImage = 224
            let iter = 0
            function processVideo() {
                iter++
                console.log('iter', iter);
                if (iter>15000) {
                    return
                }
                let begin = Date.now();
                cap.read(src);
                src.copyTo(dst);
                cv.cvtColor(dst, gray, cv.COLOR_BGR2GRAY, 0);

                try {
                    classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                    console.log(faces.size());
                } catch (err) {
                    console.log(err);
                }
                let facesData = []
                
                for (let i = 0; i < faces.size(); ++i) {
                    let structuredArray = [];
                    const face = faces.get(i);
                    const point1 = new cv.Point(face.x, face.y);
                    const point2 = new cv.Point(face.x + face.width, face.y + face.height);
                    cv.rectangle(dst, point1, point2, [0, 0, 255, 255]);
                    const faceROI = src.roi(face);
                    const roiRGB = new cv.Mat();
                    cv.cvtColor(faceROI, roiRGB, cv.COLOR_BGR2RGB); 
                    const resizedRoi = new cv.Mat();
                    cv.resize(roiRGB, resizedRoi, new cv.Size(sizeImage, sizeImage));

                    test = new cv.Mat();
                    cv.resize(roiRGB, test, new cv.Size(200, 200));
                    console.log(resizedRoi);
           
                    for (let i = 0; i < resizedRoi.rows; i++) {
                        let rowArray = [];
                        for (let j = 0; j < resizedRoi.cols; j++) {
                            let pixel = [resizedRoi.ucharPtr(i, j)[0], resizedRoi.ucharPtr(i, j)[1],resizedRoi.ucharPtr(i, j)[2]]; // B
                            //????????????????
                            rowArray.push(pixel);
                        }
                        structuredArray.push(rowArray);
                                
                }
                
                facesData.push(structuredArray)
                }
                console.log("facesData",facesData);
                let formData = new FormData();              
                    formData.append("encodings", JSON.stringify(facesData));
                    fetch('http://127.0.0.1:8000/api/reconize/', { 
                        method: 'POST',
                        body: formData, 
                        redirect: 'follow'
                    })
                    .then(response => {
                        if (!response.ok) {
                            throw new Error('Network response was not ok');
                        }
                        return response.json();
                    })
                    .then(data => console.log('Success:', data))
                    .catch((error) => console.error('Error:', error));

                cv.imshow("canvas_output", dst);
                // planifier le prochain
                let delay = 1000/FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            }
            // planifier le premier
            setTimeout(processVideo, 0);
        };
    }

    function stopCamera() {
        let trackPromises = [];
    
        videoStream.getTracks().forEach(track => {
            track.stop();
    
            let formData2 = new FormData();
            formData2.append("stop", "stop");
    
            let fetchPromise = fetch('http://127.0.0.1:8000/api/stop/', {
                method: 'POST',
                body: formData2,
                redirect: 'follow'
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.json();
            })
            .then(data => console.log('Success_Stop:', data))
            .catch(error => {
                console.error('Error:', error);
                // Même en cas d'erreur, on résout la promesse pour permettre la navigation
                return Promise.resolve();
            });
    
            trackPromises.push(fetchPromise);
        });
    
        Promise.all(trackPromises).then(() => {
            console.log("Camera arrêtée et données envoyées!");
            window.history.back();  // Utilisation de `back()` pour un comportement peut-être plus fiable
        });
    }
    function stopCamera() {
        const stopButton = document.getElementById('stopButton');
        stopButton.disabled = true; // Désactiver le bouton pour éviter les clics multiples
    
        let trackPromises = [];
    
        videoStream.getTracks().forEach(track => {
            track.stop();
    
            let formData2 = new FormData();
            formData2.append("stop", "stop");
    
            let fetchPromise = fetch('http://127.0.0.1:8000/api/stop/', {
                method: 'POST',
                body: formData2,
                redirect: 'follow'
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.json();
            })
            .then(data => {
                console.log('Success_Stop:', data);
            })
            .catch(error => {
                console.error('Error:', error);
                return Promise.resolve(); // Continue même en cas d'erreur
            });
    
            trackPromises.push(fetchPromise);
        });
    
        Promise.all(trackPromises).then(() => {
            console.log("Camera arrêtée et données envoyées!");
            stopButton.disabled = false; // Réactiver le bouton une fois que tout est terminé
            window.history.go(-1);
        });
    }
    
        
    

</script>
</body>
</html>